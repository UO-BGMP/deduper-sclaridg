{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduper Script Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inline Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1', '2', '3'}\n",
      "Yes 2\n"
     ]
    }
   ],
   "source": [
    "x = set()\n",
    "x.add(\"1\")\n",
    "x.add(\"2\")\n",
    "x.add(\"3\")\n",
    "print(x)\n",
    "\n",
    "if \"2\" in x:\n",
    "    print(\"Yes 2\")\n",
    "if \"4\" in x:\n",
    "    print(\"Yes 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [1, 2, 3], 'b': [4, 5, 7], 'c': [8, 9, 10]}\n",
      "2\n",
      "5\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "b = {'a' : [1, 2, 3], 'b' : [4, 5, 7], 'c' : [8, 9, 10]}\n",
    "#test = b.pop(\"a\")\n",
    "#print(test)\n",
    "print(b)\n",
    "\n",
    "for value in b.values():\n",
    "    print(value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two_one_three'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(num1, num2, num3):\n",
    "    return \"_\".join([num1, num2, num3])\n",
    "\n",
    "test(\"one\", \"two\", \"three\")\n",
    "test(num2 = \"one\", num1 = \"two\", num3 = \"three\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"1\", \"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_read_checker(flag):\n",
    "    '''Takes the bitwise flag.\n",
    "    Checks if reads are paired-end and halts program if reads are not.\n",
    "    Checks if reads are mapped in proper pairs and halts program if not.\n",
    "    Checks if the read is forward or reverse and returns \"forward\" or \"reverse\".'''\n",
    "    \n",
    "    # Check if reads are paired\n",
    "    if ((flag & 1) != 1):\n",
    "        raise ValueError(\"ERROR: Exiting program. This is not paired-end data.\")\n",
    "    \n",
    "    # Check if reads are mapped in proper pairs\n",
    "    if ((flag & 2) != 2):\n",
    "        raise ValueError(\"ERROR: Exiting program. Encountered reads that were not mapped in proper pairs.\")\n",
    "    \n",
    "    # Check forward or reverse\n",
    "    # Flags drived from Sequence Alignment/Map Format Specification (21 Aug 2017)\n",
    "    # https://samtools.github.io/hts-specs/SAMv1.pdf\n",
    "    \n",
    "    if ((flag & 64) == 64):\n",
    "        read = \"forward\"\n",
    "    if ((flag & 128) == 128):\n",
    "        read = \"reverse\"\n",
    "    return read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ERROR: Exiting program. This is not paired-end data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f2753eebe40e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mline_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpaired_read_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-9ca3c888fe9d>\u001b[0m in \u001b[0;36mpaired_read_checker\u001b[0;34m(flag)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Check if reads are paired\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ERROR: Exiting program. This is not paired-end data.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Check if reads are mapped in proper pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ERROR: Exiting program. This is not paired-end data."
     ]
    }
   ],
   "source": [
    "line = \"NS500451:154:HWKTMBGXX:1:12110:16730:9664:ACGAAGGT\t0\t2\t3457742\t36\t71M\t*\t0\t0\tCACAAAATACAAAATTATTTAAATGTAGTGGATAGTAATTAAAAGTGCCTGCAAGTGACCTGAATTACACT\tEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAE\tMD:Z:71\tNH:i:1\tHI:i:1\tNM:i:0\tSM:i:36\tXQ:i:40\tX2:i:0\tXO:Z:UU\"\n",
    "line_list = line.strip(\"\\n\").split(\"\\t\")\n",
    "flag = int(line_list[1])\n",
    "paired_read_checker(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created UMI dictionary.\n",
      "Opening SAM files for reading and writing.\n",
      "\n",
      "\n",
      "UMI\tCount\n",
      "AAAAAAAA\t8\n",
      "TTTTTTTT\t5\n",
      "\n",
      "\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "##### Define Higher Order Functions #################################################\n",
    "#####################################################################################\n",
    "\n",
    "def strand_checker(flag):\n",
    "    '''Takes the bitwise flag and checks it for strandedness. Assumes read is mapped, otherwise returnes None.\n",
    "    Assumes data are single-end. Returns \"+\" or \"-\", depending on strand.'''\n",
    "    # Check read is mapped\n",
    "    if ((flag & 4) == 4):\n",
    "        return None\n",
    "    # Assume positive strand\n",
    "    strand = \"+\"\n",
    "    if ((flag & 16) == 16):\n",
    "        # Changes strand if bit 16 is set\n",
    "        strand = \"-\"\n",
    "    return strand\n",
    "\n",
    "def POS_correct(cigar_string, POS):\n",
    "    '''Takes the CIGAR string and corrects the start position in the SAM file (POS)\n",
    "    according to any soft clipping at the beginning of the CIGAR string. Returns the corrected POS value.'''\n",
    "    search = re.search(r\"^\\d+S\", cigar_string)\n",
    "    if search:\n",
    "        soft_clip = int(search.group(0)[:-1])\n",
    "        corrected_POS = POS - soft_clip\n",
    "    else:\n",
    "        corrected_POS = POS\n",
    "        # Corrected starting position could be the same as the starting position\n",
    "    return corrected_POS\n",
    "\n",
    "def perbase_qscore(quality):\n",
    "    '''Calculates the average per-base quality score (assumes Phred33 encoding) \n",
    "    based on the QUAL string in the SAM entry.'''\n",
    "    score_total = 0\n",
    "    for char in quality:\n",
    "        score_total += ord(char) - 33 # Convert ASCII score to phred score\n",
    "    score = score_total / len(quality)\n",
    "    return score\n",
    "\n",
    "def count_lines(infile):\n",
    "    '''Opens the input file and returns the number of lines in the file.'''\n",
    "    with open(infile) as file:\n",
    "        for i, line in enumerate(file):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "##### Set Up ########################################################################\n",
    "#####################################################################################\n",
    "\n",
    "### Initialize empty dictionaries for tuples and dictionaries\n",
    "tuple_dict = {}\n",
    "umi_dict = {}\n",
    "\n",
    "### Make UMI dictionary\n",
    "with open(\"umi_list.txt\") as umi_list:\n",
    "    for umi in umi_list:\n",
    "        umi = umi.strip(\"\\n\")\n",
    "        umi_dict[umi] = 0\n",
    "print(\"Created UMI dictionary.\", flush = True)\n",
    "\n",
    "###Initialze chromosome variable for chromosome check in the with loop\n",
    "chromosome = 1\n",
    "\n",
    "### Create output filename\n",
    "infile = \"/Users/sally_claridge/Desktop/deduper-sclaridg/test_input.sam\"\n",
    "filename = infile.split(\"/\")[-1].split(\".\")[0]   # Isolate file name\n",
    "deduped = \"\".join([filename, \"_deduped\"])      # Add \"deduped\"\n",
    "outfile = infile.replace(filename, deduped)       # Replace in original filepath\n",
    "\n",
    "### Get file linecount\n",
    "total_lines = count_lines(infile)\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "##### Read Through SAM File #########################################################\n",
    "#####################################################################################\n",
    "\n",
    "print(\"Opening SAM files for reading and writing.\", flush = True)\n",
    "\n",
    "with open(infile, \"r+\") as file, open(outfile, \"w+\") as out:\n",
    "    linecount = 0\n",
    "    for line in file:\n",
    "        linecount += 1\n",
    "        if line.startswith(\"@\") == True:\n",
    "            pass\n",
    "        elif line.startswith(\"@\") == False:\n",
    "            line_list = line.strip(\"\\n\").split(\"\\t\")\n",
    "            \n",
    "            ### Progress report\n",
    "            if linecount % 200000 == 0:\n",
    "                print(\"Passed line\" + str(linecount) + \".\", flush = True)\n",
    "            \n",
    "            ### Check UMI\n",
    "            umi = line_list[0].split(\":\")[-1]\n",
    "            if umi in umi_dict:\n",
    "                umi_dict[umi] +=1\n",
    "            else:\n",
    "                if linecount == total_lines:\n",
    "                    for value in tuple_dict.values():\n",
    "                        out.write(value)\n",
    "                continue\n",
    "                \n",
    "            ### Check bitwise flag\n",
    "            flag = int(line_list[1])\n",
    "            strand = strand_checker(flag)\n",
    "            \n",
    "            ### Check chromosome\n",
    "            prev_chromosome = chromosome\n",
    "            chromosome = line_list[2]\n",
    "            if chromosome != prev_chromosome:\n",
    "                for value in tuple_dict.values():\n",
    "                    out.write(value)\n",
    "                tuple_dict = {}\n",
    "            \n",
    "            ### Check POS and CIGAR string\n",
    "            POS = int(line_list[3])\n",
    "            cigar_string = line_list[5]\n",
    "            new_POS = POS_correct(cigar_string, POS)\n",
    "            \n",
    "            ### Calculate average quality score across the alignment\n",
    "            quality = line_list[10]\n",
    "            score = perbase_qscore(quality)\n",
    "            \n",
    "            ### Check tuple_dict\n",
    "            query_tuple = (umi, strand, chromosome, new_POS)\n",
    "            if query_tuple in tuple_dict:\n",
    "                existing_quality = tuple_dict[query_tuple].split(\"\\t\")[10]\n",
    "                existing_score = perbase_qscore(existing_quality)\n",
    "                if existing_score >= score:\n",
    "                    pass\n",
    "                elif existing_score < score:\n",
    "                    tuple_dict[query_tuple] = line\n",
    "            if query_tuple not in tuple_dict:\n",
    "                tuple_dict[query_tuple] = line\n",
    "                \n",
    "            ### Last line check\n",
    "            if linecount == total_lines:\n",
    "                for value in tuple_dict.values():\n",
    "                    out.write(value)\n",
    "\n",
    "### Print closing remarks\n",
    "print(\"\\n\")\n",
    "print(\"UMI\\tCount\", flush = True)\n",
    "for k, v in umi_dict.items():\n",
    "    print(str(k) + \"\\t\" + str(v), flush = True)\n",
    "\n",
    "print(\"\\n\") \n",
    "print(\"Finished.\", flush = True)\n",
    "#sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax with `argparse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#claridge_deduper.py\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "import sys\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Removes PCR duplicates from a SAM file of sorted (using samtools) and uniquely mapped reads (single- and paired-end). For each set of duplicates, the duplicate with the highest per-base average quality is printed to an output file. Given a list of known UMIs, alignments with unexpected UMIs are ignored.\")\n",
    "parser.add_argument('-f','--file', help='absolute path to SAM file to be deduped.', required=True, type=str)\n",
    "parser.add_argument('-p','--paired', help='reads are paired-end.', required=False, action='store_true', default=False)\n",
    "parser.add_argument('-u','--umi', help='absolute path to list of UMIs (default: randomers were used).', required=False, type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "##### Define Higher Order Functions #################################################\n",
    "#####################################################################################\n",
    "\n",
    "def strand_checker(flag):\n",
    "    '''Takes the bitwise flag and checks it for strandedness. Assumes read is mapped, otherwise returnes None.\n",
    "    Assumes data are single-end. Returns \"+\" or \"-\", depending on strand.'''\n",
    "    # Check read is mapped\n",
    "    if ((flag & 4) == 4):\n",
    "        raise NameError(\"Exiting program. Read is unmapped.\")\n",
    "        return None\n",
    "    # Assume positive strand\n",
    "    strand = \"+\"\n",
    "    if ((flag & 16) == 16):\n",
    "        # Changes strand if bit 16 is set\n",
    "        strand = \"-\"\n",
    "    return strand\n",
    "\n",
    "def read_checker(flag):\n",
    "    '''Takes the bitwise flag and checks whether the reads are paired-end or not.\n",
    "    Halts program if reads are unpaired. Returns \"forward\" or \"reverse\", depending on the read.'''\n",
    "    # Check if reads are paired\n",
    "    if ((flag & 1) != 1):\n",
    "        raise NameError(\"Exiting program. This is not paried-end data.\")\n",
    "        return None\n",
    "    if ((flag & 40) == 40):\n",
    "        read = \"forward\"\n",
    "    if ((flag & 80) == 80):\n",
    "        read = \"reverse\"\n",
    "    return read\n",
    "\n",
    "def POS_correct(cigar_string, POS):\n",
    "    '''Takes the CIGAR string and corrects the start position in the SAM file (POS)\n",
    "    according to any soft clipping at the beginning of the CIGAR string. Returns the corrected POS value.'''\n",
    "    # Find soft clippling in begining of cigar string\n",
    "    search = re.search(r\"^\\d+S\", cigar_string)\n",
    "    # If soft clipping found\n",
    "    if search:\n",
    "        soft_clip = int(search.group(0)[:-1])\n",
    "        corrected_POS = POS - soft_clip\n",
    "    # If soft clipping not found\n",
    "    else:\n",
    "        corrected_POS = POS\n",
    "        # Corrected starting position could be the same as the starting position\n",
    "    return corrected_POS\n",
    "\n",
    "def perbase_qscore(quality):\n",
    "    '''Calculates the average per-base quality score (assumes Phred33 encoding) \n",
    "    based on the QUAL string in the SAM entry.'''\n",
    "    score_total = 0\n",
    "    for char in quality:\n",
    "        score_total += ord(char) - 33 # Convert ASCII score to phred score\n",
    "    score = score_total / len(quality)\n",
    "    return score\n",
    "\n",
    "def count_lines(infile):\n",
    "    '''Opens the input file and returns the number of lines in the file.'''\n",
    "    with open(infile) as file:\n",
    "        for i, line in enumerate(file):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "##### Set Up ########################################################################\n",
    "#####################################################################################\n",
    "\n",
    "### Initialize empty dictionaries for tuples and dictionaries\n",
    "# tuple_dict will contain tuples as keys and SAM entries with highest average per-base quality as values\n",
    "# Format of tuples: (umi/randomer, strand +/-, chromosome, new_POS, read forward/reverse/na)\n",
    "tuple_dict = {}\n",
    "# umi_dict will store UMIs or randomers as keys and counts as values\n",
    "umi_dict = {}\n",
    "# Make UMI dictionary if UMI flag is set, otherwise leave empty\n",
    "if args.umi is not None:\n",
    "    with open(args.umi) as umi_list:\n",
    "        for umi in umi_list:\n",
    "            umi = umi.strip(\"\\n\")\n",
    "            umi_dict[umi] = 0\n",
    "    print(\"Created UMI dictionary.\", flush = True)\n",
    "\n",
    "### Initialze first_line and read variables\n",
    "# Used in chromosome check\n",
    "first_line = True\n",
    "# Read will be a non-factor in single-end data, but will be edited if paired flag set\n",
    "read = \"na\"\n",
    "\n",
    "### Create output filename\n",
    "infile = \"/Users/sally_claridge/Desktop/deduper-sclaridg/test_input.sam\"\n",
    "filename = infile.split(\"/\")[-1].split(\".\")[0]   # Isolate file name\n",
    "deduped = \"\".join([filename, \"_deduped\"])        # Add \"deduped\"\n",
    "outfile = infile.replace(filename, deduped)      # Replace in original filepath\n",
    "\n",
    "### Get file linecount to be used in last line check\n",
    "total_lines = count_lines(infile)\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "##### Read Through SAM File #########################################################\n",
    "#####################################################################################\n",
    "\n",
    "print(\"Opening SAM files for reading and writing.\", flush = True)\n",
    "\n",
    "with open(infile, \"r+\") as file, open(outfile, \"w+\") as out:\n",
    "    linecount = 0\n",
    "    for line in file:\n",
    "        linecount += 1\n",
    "        if line.startswith(\"@\") == True:\n",
    "            pass\n",
    "        elif line.startswith(\"@\") == False:\n",
    "            line_list = line.strip(\"\\n\").split(\"\\t\")\n",
    "            \n",
    "            ### Progress report\n",
    "            if linecount % 200000 == 0:\n",
    "                print(\"Passed line\" + str(linecount) + \".\", flush = True)\n",
    "            \n",
    "            ### Check UMI\n",
    "            umi = line_list[0].split(\":\")[-1]\n",
    "            if args.umi is None:                  # If UMI flag was not set, assume randomers\n",
    "                if umi in umi_dict:\n",
    "                    umi_dict[umi] +=1\n",
    "                else:\n",
    "                    umi_dict[umi] = 1             # Still use umi_dict, but store randomers instead of UMIs\n",
    "            elif args.umi is not None:            # If UMI flag was set\n",
    "                if umi in umi_dict:\n",
    "                    umi_dict[umi] +=1\n",
    "            else:\n",
    "                if linecount == total_lines:      # If last line in file, print dictionary contents\n",
    "                    for value in tuple_dict.values():\n",
    "                        out.write(value)\n",
    "                continue                          # Do not write unexpexted UMI alignment to file\n",
    "                \n",
    "            ### Check bitwise flag\n",
    "            flag = int(line_list[1])\n",
    "            # Check strand\n",
    "            strand = strand_checker(flag)\n",
    "            # Check read (if paired flag set)\n",
    "            if args.paired:\n",
    "                read = read_checker(flag)\n",
    "                \n",
    "            ### Check chromosome\n",
    "            # If first line, set the chromosome variable\n",
    "            if first_line == True:\n",
    "                chromosome = line_list[2]\n",
    "                first_line == False\n",
    "            # If not the first line, run chromosome check for emptying tuple_dict\n",
    "            elif first_line == False:\n",
    "                prev_chromosome = chromosome\n",
    "                chromosome = line_list[2]\n",
    "                if chromosome != prev_chromosome:  # Inequality means that you have switched chromosomes\n",
    "                    for value in tuple_dict.values():\n",
    "                        out.write(value)           # Print tuple_dict contents to output file\n",
    "                    tuple_dict = {}                # Empty tuple_dict\n",
    "            \n",
    "            ### Check POS and CIGAR string (correcting for soft clipping if necessary)\n",
    "            POS = int(line_list[3])\n",
    "            cigar_string = line_list[5]\n",
    "            new_POS = POS_correct(cigar_string, POS)\n",
    "            \n",
    "            ### Calculate average per-base quality score across the alignment\n",
    "            quality = line_list[10]\n",
    "            score = perbase_qscore(quality)\n",
    "            \n",
    "            ### Check tuple_dict\n",
    "            # Make tuple\n",
    "            query_tuple = (umi, strand, chromosome, new_POS, read)\n",
    "            if query_tuple in tuple_dict:\n",
    "                # Check existing score against new alignment's score, replace if new alignments's is higher\n",
    "                existing_quality = tuple_dict[query_tuple].split(\"\\t\")[10]\n",
    "                existing_score = perbase_qscore(existing_quality)\n",
    "                if existing_score >= score:\n",
    "                    pass\n",
    "                elif existing_score < score:\n",
    "                    tuple_dict[query_tuple] = line\n",
    "            if query_tuple not in tuple_dict:\n",
    "                # Add alignment if tuple not found in tuple_dict\n",
    "                tuple_dict[query_tuple] = line\n",
    "                \n",
    "            ### Last line check\n",
    "            if linecount == total_lines:\n",
    "                for value in tuple_dict.values():\n",
    "                    out.write(value)\n",
    "\n",
    "### Print closing remarks/stats       \n",
    "print(\"\\n\")\n",
    "if args.umi is None:\n",
    "    print(\"%s randomers were identified.\" % len(umi_dict), flush = True)\n",
    "elif args.umi is not None:\n",
    "    print(\"Molecular_Identifier\\tCount\", flush = True)\n",
    "    for k, v in umi_dict.items():\n",
    "        print(str(k) + \"\\t\" + str(v), flush = True)\n",
    "\n",
    "print(\"\\n\") \n",
    "print(\"Finished.\", flush = True)\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#claridge_deduper_v2.py\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "import sys\n",
    "import textwrap\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Removes PCR duplicates from a SAM file of sorted (using samtools) and uniquely mapped reads (single- and paired-end). For each set of duplicates, one duplicate is printed to an output file. Given a list of known UMIs, alignments with unexpected UMIs are ignored. If the reads are paired, assumes reads are mapped in proper pairs\", formatter_class=argparse.RawTextHelpFormatter)\n",
    "parser.add_argument('-f','--file', help='absolute path to SAM file to be deduped', required=True, type=str)\n",
    "parser.add_argument('-p','--paired', help='if flag is set, indicates that reads are paired-end (default: single-end)', required=False, action='store_true', default=False)\n",
    "parser.add_argument('-u','--umi', help='absolute path to list of UMIs (default: randomers)', required=False, type=str)\n",
    "parser.add_argument('-q','--quality_filter', help=textwrap.dedent('''if flag is set, duplicates will be quality filtered (default: first encountered duplicate)\n",
    "note that for paired-end reads, quality filter is dictated by forward read only\n",
    "options:\n",
    "perbase   select duplicate with the highest per-base average quality\n",
    "mapq      select duplicate with the highest MAPQ value'''), required=False, default=False)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "##### Define Higher Order Functions ######################################################\n",
    "##########################################################################################\n",
    "\n",
    "def strand_checker(flag):\n",
    "    '''Takes the bitwise flag and checks it for strandedness.\n",
    "    Assumes read is mapped, otherwise returnes None.\n",
    "    Assumes data are single-end. Returns \"+\" or \"-\", depending on strand.'''\n",
    "    \n",
    "    # Check read is mapped\n",
    "    if ((flag & 4) == 4):\n",
    "        raise NameError(\"ERROR: Exiting program. Read is unmapped.\")\n",
    "    \n",
    "    # Assume positive strand\n",
    "    strand = \"+\"\n",
    "    if ((flag & 16) == 16):\n",
    "        # Changes strand if bit 16 is set\n",
    "        strand = \"-\"\n",
    "    return strand\n",
    "\n",
    "def paired_read_checker(flag):\n",
    "    '''Takes the bitwise flag.\n",
    "    Checks if reads are paired-end and halts program if reads are not.\n",
    "    Checks if reads are mapped in proper pairs and halts program if not.\n",
    "    Checks if the read is forward or reverse and returns \"forward\" or \"reverse\".'''\n",
    "    \n",
    "    # Check if reads are paired\n",
    "    if ((flag & 1) != 1):\n",
    "        raise ValueError(\"ERROR: Exiting program. This is not paired-end data.\")\n",
    "    \n",
    "    # Check if reads are mapped in proper pairs\n",
    "    if ((flag & 2) != 2):\n",
    "        raise ValueError(\"ERROR: Exiting program. Encountered reads that were not mapped in proper pairs.\")\n",
    "    \n",
    "    # Check forward or reverse\n",
    "    # Flags drived from Sequence Alignment/Map Format Specification (21 Aug 2017)\n",
    "    # https://samtools.github.io/hts-specs/SAMv1.pdf\n",
    "    \n",
    "    if ((flag & 64) == 64):\n",
    "        read = \"forward\"\n",
    "    if ((flag & 128) == 128):\n",
    "        read = \"reverse\"\n",
    "    return read\n",
    "\n",
    "def POS_correct(cigar_string, POS):\n",
    "    '''Takes the CIGAR string and corrects the start position in the SAM file (POS)\n",
    "    according to any soft clipping at the beginning of the CIGAR string.\n",
    "    Returns the corrected POS value.'''\n",
    "    \n",
    "    # Find soft clippling in begining of cigar_string\n",
    "    search = re.search(r\"^\\d+S\", cigar_string)\n",
    "    \n",
    "    # If soft clipping found\n",
    "    if search:\n",
    "        soft_clip = int(search.group(0)[:-1])\n",
    "        corrected_POS = POS - soft_clip\n",
    "    \n",
    "    # If soft clipping not found\n",
    "    else:\n",
    "        corrected_POS = POS\n",
    "        # Corrected starting position could be the same as the starting position\n",
    "    return corrected_POS\n",
    "\n",
    "def paired_corrections(cigar_string_f, cigar_string_r, POS_f, TLEN_f):\n",
    "    '''For paired-end reads.\n",
    "    Calculates corrected_POS for the first read via POS_correct function.\n",
    "    Adds the TLEN to the corrected_POS, yielding the putative end of the template.\n",
    "    Takes the CIGAR string of the second read and corrects the TLEN if soft clipping occurred.\n",
    "    Returns the corrected TLEN value.'''\n",
    "    corrected_POS = POS_correct(cigar_string_f, POS_f)\n",
    "    end_TLEN = corrected_POS + TLEN_f\n",
    "\t\n",
    "\t# Find soft clippling in begining of cigar_string2\n",
    "    search = re.search(r\"^\\d+S\", cigar_string_r)\n",
    "    \n",
    "    # If soft clipping found\n",
    "    if search:\n",
    "        soft_clip = int(search.group(0)[:-1])\n",
    "        corrected_TLEN = end_TLEN + soft_clip\n",
    "    \n",
    "    # If soft clipping not found\n",
    "    else:\n",
    "        corrected_TLEN = end_TLEN\n",
    "\t\n",
    "    return [corrected_POS, corrected_TLEN]\n",
    "\n",
    "def perbase_qscore(quality):\n",
    "    '''Calculates the average per-base quality score (assumes Phred33 encoding) \n",
    "    based on the QUAL string in the SAM entry.'''\n",
    "    score_total = 0\n",
    "    for char in quality:\n",
    "        score_total += ord(char) - 33 # Convert ASCII score to phred score\n",
    "    score = score_total / len(quality)\n",
    "    return score\n",
    "\n",
    "def count_lines(infile):\n",
    "    '''Opens the input file and returns the number of lines in the file.'''\n",
    "    with open(infile) as file:\n",
    "        for i, line in enumerate(file):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "##### Set Up #############################################################################\n",
    "##########################################################################################\n",
    "\n",
    "### Initialize empty dictionary for tuples\n",
    "# tuple_dict will contain tuples as keys and SAM entries with highest average per-base quality as values\n",
    "# Format of single-end tuples: (umi/randomer, strand +/-, chromosome, new_POS)\n",
    "# Format of paired-end tuples: (umi/randomer pair, strand +/-, chromosome, new_POS, new_TLEN)\n",
    "tuple_dict = {}\n",
    "\n",
    "### Initialize empty set for UMIs if flag is set\n",
    "# Make UMI set if UMI flag is set, otherwise leave empty\n",
    "if args.umi is not None:\n",
    "    umi_set = set()\n",
    "    print(\"Creating UMI set:\")\n",
    "    with open(args.umi, \"r+\") as umi_list:\n",
    "        for umi in umi_list:\n",
    "            umi = umi.strip(\"\\n\")\n",
    "            print(\"\\t\" + umi)\n",
    "            umi_set.add(umi)\n",
    "    \n",
    "\n",
    "### Initialze first_line variable used in chromosome check\n",
    "first_line = True\n",
    "\n",
    "### Create output filename\n",
    "infile = args.file\n",
    "filename = infile.split(\"/\")[-1].split(\".\")[0]   # Isolate file name\n",
    "deduped = \"\".join([filename, \"_deduped\"])        # Add \"deduped\"\n",
    "outfile = infile.replace(filename, deduped)      # Replace in original filepath\n",
    "\n",
    "### Get file linecount to be used in last line check\n",
    "total_lines = count_lines(infile)\n",
    "\n",
    "print(\"Opening %s.sam for reading and %s.sam for writing.\" % (filename, deduped))\n",
    "\n",
    "if args.quality_filter == False:\n",
    "\tprint(\"Quality filter: Default.\")\n",
    "elif args.quality_filter == \"perbase\":\n",
    "\tprint(\"Quality filter: Average per-base quality score.\") \n",
    "elif args.quality_filter == \"mapq\": \n",
    "\tprint(\"Quality filter: mapq.\") \n",
    "\t\n",
    "\t\n",
    "\t\n",
    "##########################################################################################\n",
    "##### Read Through SAM File ##############################################################\n",
    "##########################################################################################\n",
    "\n",
    "##### Single-End #########################################################################\n",
    "\n",
    "if args.paired == False:\n",
    "\tprint(\"Read type: Single-end.\")\n",
    "\twith open(infile, \"r+\") as file, open(outfile, \"w+\") as out:\n",
    "\t\tlinecount = 0\n",
    "\t\twhile True:\n",
    "\t\t\tline = file.readline()\n",
    "\t\t\n",
    "\t\t\t### Last line check\n",
    "\t\t\tif line == \"\":\n",
    "\t\t\t\tif args.quality_filter == False:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\tif args.quality_filter != False:\n",
    "\t\t\t\t\tfor value in tuple_dict.values():\n",
    "\t\t\t\t\t\tout.write(value)\n",
    "\t\t\t\tbreak\n",
    "\t\t\n",
    "\t\t\tlinecount += 1\n",
    "\t\t\n",
    "\t\t\t### Print out header lines\n",
    "\t\t\tif line.startswith(\"@\") == True:\n",
    "\t\t\t\tout.write(line)\n",
    "\t\t\n",
    "\t\t\t### Process alignments\n",
    "\t\t\telif line.startswith(\"@\") == False:\n",
    "\t\t\t\tline_list = line.strip(\"\\n\").split(\"\\t\")\n",
    "\t\t\n",
    "\t\t\t\t### Progress report\n",
    "\t\t\t\tif linecount % 200000 == 0:\n",
    "\t\t\t\t\tprint(\"Passed line \" + str(linecount) + \".\")\n",
    "\t\t  \n",
    "\t\t\t\t### Check bitwise flag\n",
    "\t\t\t\tflag = int(line_list[1])\n",
    "\t\t\t\t# Check strand\n",
    "\t\t\t\tstrand = strand_checker(flag)\n",
    "\n",
    "\t\t\t\t### Check UMI\n",
    "\t\t\t\tumi = line_list[0].split(\":\")[-1]\n",
    "\t\t\t\tif args.umi is None:                  # If UMI flag was not set, assume randomers and do nothing\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\telif args.umi is not None:            # If UMI flag was set\n",
    "\t\t\t\t\tif umi in umi_set:\t\t\t\t  # If UMI is in the umi_set, do nothing\n",
    "\t\t\t\t\t\tpass\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif linecount == total_lines:      # If last line in file, print tuple_dict contents and break\n",
    "\t\t\t\t\t\t\tfor value in tuple_dict.values():\n",
    "\t\t\t\t\t\t\t\tout.write(value)\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\tcontinue                          # Do not write unexpexted alignment with unexpected UMI to file\n",
    "\t\t   \n",
    "\t\t\t\t### Check chromosome\n",
    "\t\t\t\t# If first line, set the chromosome variable\n",
    "\t\t\t\tif first_line == True:\n",
    "\t\t\t\t\tchromosome = line_list[2]\n",
    "\t\t\t\t\tfirst_line == False\n",
    "\t\t\t\t# If not the first line, run chromosome check for emptying tuple_dict\n",
    "\t\t\t\telif first_line == False:\n",
    "\t\t\t\t\tprev_chromosome = chromosome\n",
    "\t\t\t\t\tchromosome = line_list[2]\n",
    "\t\t\t\t\tif chromosome != prev_chromosome:  # Inequality means that you have switched chromosomes\n",
    "\t\t\t\t\t\tfor value in tuple_dict.values():\n",
    "\t\t\t\t\t\t\tout.write(value)           # Print tuple_dict contents to output file\n",
    "\t\t\t\t\t\ttuple_dict = {}                # Empty tuple_dict\n",
    "\t\t\n",
    "\t\t\t\t### Check POS and CIGAR string (correcting for soft clipping if necessary)\n",
    "\t\t\t\tPOS = int(line_list[3])\n",
    "\t\t\t\tcigar_string = line_list[5]\n",
    "\t\t\t\tnew_POS = POS_correct(cigar_string, POS)\n",
    "\t\t\t\n",
    "\t\t\t\t### Make tuple\n",
    "\t\t\t\tquery_tuple = (umi, strand, chromosome, new_POS)\t\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t\t### Check tuple_dict, method depending on quality_filter flag\n",
    "\t\t\t\tif args.quality_filter == False:\n",
    "\t\t\t\t\tif query_tuple not in tuple_dict:\n",
    "\t\t\t\t\t\ttuple_dict[query_tuple] = 1\n",
    "\t\t\t\t\t\tout.write(line)\n",
    "\t\t\t\t\telif query_tuple in tuple_dict:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\telif args.quality_filter == \"perbase\": \t\n",
    "\t\t\t\t\t# Calculate average per-base quality score across the alignment\n",
    "\t\t\t\t\tquality = line_list[10]\n",
    "\t\t\t\t\tscore = perbase_qscore(quality)\n",
    "\t\t\t\t\tif query_tuple in tuple_dict:\n",
    "\t\t\t\t\t\t# Check existing score against new alignment's score, replace if new alignments's is higher\n",
    "\t\t\t\t\t\texisting_quality = tuple_dict[query_tuple].split(\"\\t\")[10]\n",
    "\t\t\t\t\t\texisting_score = perbase_qscore(existing_quality)\n",
    "\t\t\t\t\t\tif existing_score >= score:\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\telif existing_score < score:\n",
    "\t\t\t\t\t\t\ttuple_dict[query_tuple] = line\n",
    "\t\t\t\t\tif query_tuple not in tuple_dict:\n",
    "\t\t\t\t\t\t# Add alignment if tuple not found in tuple_dict\n",
    "\t\t\t\t\t\ttuple_dict[query_tuple] = line\n",
    "\t\t\t\telif args.quality_filter == \"mapq\": \t\n",
    "\t\t\t\t\tMAPQ = line_list[4]\n",
    "\t\t\t\t\tif query_tuple in tuple_dict:\n",
    "\t\t\t\t\t\t# Check existing MAPQ against new alignment's MAPQ, replace if new alignments's is higher\n",
    "\t\t\t\t\t\texisting_MAPQ = tuple_dict[query_tuple].split(\"\\t\")[4]\n",
    "\t\t\t\t\t\tif existing_MAPQ >= MAPQ:\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\telif existing_MAPQ < MAPQ:\n",
    "\t\t\t\t\t\t\ttuple_dict[query_tuple] = line\n",
    "\t\t\t\t\tif query_tuple not in tuple_dict:\n",
    "\t\t\t\t\t\t# Add alignment if tuple not found in tuple_dict\n",
    "\t\t\t\t\t\ttuple_dict[query_tuple] = line\n",
    "\t\t\t\t\t\n",
    "##### Paired-End #########################################################################\n",
    "\n",
    "if args.paired == True:\n",
    "\tprint(\"Read type: Paired-end.\")\n",
    "\twith open(infile, \"r+\") as file, open(outfile, \"w+\") as out:\n",
    "\t\tlinecount = 0\n",
    "\t\theader_count = 0\n",
    "\t\tsingleton_dict = {}\n",
    "\t\twhile True:\n",
    "\t\t\tline1 = file.readline()\n",
    "\t\t\tlinecount += 1\n",
    "\t\t\t\n",
    "\t\t\t### Progress report\n",
    "\t\t\tif linecount % 200000 == 0:\n",
    "\t\t\t\tprint(\"Passed line \" + str(linecount) + \".\")\n",
    "\t\t\t\t\n",
    "\t\t\t### Print out header lines\n",
    "\t\t\tif line1.startswith(\"@\") == True:\n",
    "\t\t\t\tout.write(line1)\n",
    "\t\t\n",
    "\t\t\t### Process alignments\n",
    "\t\t\telif line1.startswith(\"@\") == False:\n",
    "\t\t\t\t### Last line check\n",
    "\t\t\t\tif line1 == \"\":\n",
    "\t\t\t\t\tif args.quality_filter == False:\n",
    "\t\t\t\t\t\tpass\n",
    "\t\t\t\t\tif args.quality_filter != False:\n",
    "\t\t\t\t\t\tfor value in tuple_dict.values():\n",
    "\t\t\t\t\t\t\tout.write(value[0])\n",
    "\t\t\t\t\t\t\tout.write(value[1])\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\t\t### Check if paired reads are adjacent in sorted SAM file\n",
    "\t\t\t\tline1_list = line1.strip(\"\\n\").split(\"\\t\")\n",
    "\t\t\t\tQNAME = line1_list[0]\t\t\t\n",
    "\t\t\t\tif QNAME not in singleton_dict:\n",
    "\t\t\t\t\tsingleton_dict[QNAME] = line1\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\telif QNAME in singleton_dict:\n",
    "\t\t\t\t\tline2 = singleton_dict.pop(QNAME)\t      # Remove singleton from dictionary and save value to new variable\n",
    "\t\t\t\t\tline2_list = line2.strip(\"\\n\").split(\"\\t\")\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t### Check UMI\n",
    "\t\t\t\t\tumi = line1_list[0].split(\":\")[-1]\n",
    "\t\t\t\t\tif args.umi is None:                      # If UMI flag was not set, assume randomers and do nothing\n",
    "\t\t\t\t\t\tpass\n",
    "\t\t\t\t\telif args.umi is not None:                # If UMI flag was set\n",
    "\t\t\t\t\t\tumi_a = umi.split(\"^\")[0]\n",
    "\t\t\t\t\t\tumi_b = umi.split(\"^\")[1]\n",
    "\t\t\t\t\t\tif umi_a in umi_set and umi_b in umi_set:\t\t\t\t  # If both UMIs are in the umi_set, do nothing\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tif linecount >= total_lines:      # If last line in file or an empty line, print tuple_dict contents and break\n",
    "\t\t\t\t\t\t\t\tfor value in tuple_dict.values():\n",
    "\t\t\t\t\t\t\t\t\tout.write(value)\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\tcontinue                          # Do not write unexpexted alignment with unexpected UMI to file\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t### Check bitwise flags\n",
    "\t\t\t\t\tflag1 = int(line1_list[1])\n",
    "\t\t\t\t\tflag2 = int(line2_list[1])\n",
    "\n",
    "\t\t\t\t\t# Check read for line1 and line2\n",
    "\t\t\t\t\tread1 = paired_read_checker(flag1)\n",
    "\t\t\t\t\tread2 = paired_read_checker(flag2)\n",
    "\t\t\t\t\t# Reassign line and line_list variable names to f (forward) and r (reverse) based on read\n",
    "\t\t\t\t\tif read1 == \"reverse\" and read2 == \"forward\":\n",
    "\t\t\t\t\t\tline_f = line2\n",
    "\t\t\t\t\t\tline_r = line1\n",
    "\t\t\t\t\t\tflag_f = flag2\n",
    "\t\t\t\t\t\tline_f_list = line2_list\n",
    "\t\t\t\t\t\tline_r_list = line1_list\n",
    "\t\t\t\t\telif read2 == \"reverse\" and read1 == \"forward\":\n",
    "\t\t\t\t\t\tline_f = line1\n",
    "\t\t\t\t\t\tline_r = line2\n",
    "\t\t\t\t\t\tflag_f = flag1\n",
    "\t\t\t\t\t\tline_f_list = line1_list\n",
    "\t\t\t\t\t\tline_r_list = line2_list\n",
    "\t\t\t\t\t# Check strand\n",
    "\t\t\t\t\tstrand = strand_checker(flag_f)\n",
    "\n",
    "\t\t\t\t\t### Check chromosome\n",
    "\t\t\t\t\t# If first line, set the chromosome variable\n",
    "\t\t\t\t\tif first_line == True:\n",
    "\t\t\t\t\t\tchromosome = line_f_list[2]\n",
    "\t\t\t\t\t\tfirst_line == False\n",
    "\t\t\t\t\t# If not the first line, run chromosome check for emptying tuple_dict\n",
    "\t\t\t\t\telif first_line == False:\n",
    "\t\t\t\t\t\tprev_chromosome = chromosome\n",
    "\t\t\t\t\t\tchromosome = line_f_list[2]\n",
    "\t\t\t\t\t\tif chromosome != prev_chromosome:  # Inequality means that you have switched chromosomes\n",
    "\t\t\t\t\t\t\tfor value in tuple_dict.values():\n",
    "\t\t\t\t\t\t\t\tout.write(value)           # Print tuple_dict contents to output file\n",
    "\t\t\t\t\t\t\ttuple_dict = {}                # Empty tuple_dict\n",
    "\t\t\n",
    "\t\t\t\t\t### Check POS, TLEN, and CIGAR string (correcting for soft clipping if necessary)\n",
    "\t\t\t\t\tcigar_string_f = line_f_list[5]\n",
    "\t\t\t\t\tcigar_string_r = line_r_list[5]\n",
    "\t\t\t\t\tPOS_f = int(line_f_list[3])\n",
    "\t\t\t\t\tTLEN_f = int(line_f_list[8])\n",
    "\t\t\t\t\t# Produce corrected_POS and corrected_TLEN with paired_corrections function\n",
    "\t\t\t\t\tcorrections = paired_corrections(cigar_string_f, cigar_string_r, POS_f, TLEN_f)\n",
    "\t\t\t\t\tnew_POS = corrections[0]\n",
    "\t\t\t\t\tnew_TLEN = corrections[1]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t### Make tuple\n",
    "\t\t\t\t\tquery_tuple = (umi, strand, chromosome, new_POS, new_TLEN)\t\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t\t\t### Check tuple_dict, method depending on quality_filter flag\n",
    "\t\t\t\t\tif args.quality_filter == False:\n",
    "\t\t\t\t\t\tif query_tuple not in tuple_dict:\n",
    "\t\t\t\t\t\t\ttuple_dict[query_tuple] = 1\n",
    "\t\t\t\t\t\t\tout.write(line_f)\n",
    "\t\t\t\t\t\t\tout.write(line_r)\n",
    "\t\t\t\t\t\telif query_tuple in tuple_dict:\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\telif args.quality_filter == \"perbase\":  \t\n",
    "\t\t\t\t\t\t# Calculate average per-base quality score across the forward read\n",
    "\t\t\t\t\t\tquality = line_f_list[10]\n",
    "\t\t\t\t\t\tscore = perbase_qscore(quality)\n",
    "\t\t\t\t\t\tif query_tuple in tuple_dict:\n",
    "\t\t\t\t\t\t\t# Check existing score against new alignment's score, replace if new alignments's is higher\n",
    "\t\t\t\t\t\t\texisting_quality = tuple_dict[query_tuple][0].split(\"\\t\")[10]\n",
    "\t\t\t\t\t\t\texisting_score = perbase_qscore(existing_quality)\n",
    "\t\t\t\t\t\t\tif existing_score >= score:\n",
    "\t\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\t\telif existing_score < score:\n",
    "\t\t\t\t\t\t\t\ttuple_dict[query_tuple] = [line_f, line_r]\n",
    "\t\t\t\t\t\tif query_tuple not in tuple_dict:\n",
    "\t\t\t\t\t\t\t# Add reads to tuple_dict if tuple not found in tuple_dict\n",
    "\t\t\t\t\t\t\ttuple_dict[query_tuple] = [line_f, line_r]\n",
    "\t\t\t\t\telif args.quality_filter == \"mapq\":\t\n",
    "\t\t\t\t\t\tMAPQ = line_f_list[4]\n",
    "\t\t\t\t\t\tif query_tuple in tuple_dict:\n",
    "\t\t\t\t\t\t\t# Check existing MAPQ against new alignment's MAPQ, replace if new alignments's is higher\n",
    "\t\t\t\t\t\t\texisting_MAPQ = tuple_dict[query_tuple][0].split(\"\\t\")[4]\n",
    "\t\t\t\t\t\t\tif existing_MAPQ >= MAPQ:\n",
    "\t\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\t\telif existing_MAPQ < MAPQ:\n",
    "\t\t\t\t\t\t\t\ttuple_dict[query_tuple] = [line_f, line_r]\n",
    "\t\t\t\t\t\tif query_tuple not in tuple_dict:\n",
    "\t\t\t\t\t\t\t# Add alignment if tuple not found in tuple_dict\n",
    "\t\t\t\t\t\t\ttuple_dict[query_tuple] = [line_f, line_r]\n",
    "\t\t\t\t\t\t\t\n",
    "print(\"Finished.\")\n",
    "sys.exit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
